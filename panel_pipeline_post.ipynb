{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a few past blog posts, we have given some examples of how to build dashboards using panel.  These have all been one stage examples, but you can actually use panel to build a pipeline of stages with information that is carried over from one stage to the next.  \n",
    "\n",
    "I have recently been learning a bit of Natural Language processing (NLP) for various texts, particulary ways to prepare and clean the data. I thought it may be kind of interesting to create a simple panel app that walks you through some of these steps.  If you are interesting in learning more about these pre-processing steps, please check out this post (here).  In this particular post, I will be focusing on how to build the app, and not as much on the steps included in the app.\n",
    "\n",
    "First, let me show you an example of a simple pipeline just to give you an idea of how easy it is to put this into place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will start by importing panel, then instantiating a panel pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "dag = pn.pipeline.Pipeline(inherit_params=False, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can add stages to the pipeline.  In order to this, we need stages to add.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a panel pipeline to work, you must create paramterized classes.  This means we will inherit from the `param.Parameterized` class.  You must also include a `panel` method for each stage that will determine the layout of the widgets you are including in your app.  \n",
    "\n",
    "Furthermore, if you plan to pass values from one stage to the next, you will need to define an `output` method that returns the values to pass to the next stage.  The stage receiving the values must include variables at the onset that will consume these values.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, `stage1` will display a text input widget and a continue button.  The text typed in stage 1 will be passed to the next stage.  In order to do that I have defined a `text` string parameter and an `output` method with the `param.output('text')` decorator.  This indicates that `text` is the output of this stage.\n",
    "\n",
    "I also want to point out here that I included a `ready` parameter.  These can be useful in order to control when the stage is complete and ready to move to the next.  Later, you will see how it is used in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "class stage1(param.Parameterized):\n",
    "    \n",
    "    ready = param.Boolean(\n",
    "        default=False,\n",
    "        doc='trigger for moving to the next page',\n",
    "        )   \n",
    "    \n",
    "    text = param.String()\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.text_input = pn.widgets.TextInput(name='Text Input', placeholder='Enter a string here...')\n",
    "        self.continue_button = pn.widgets.Button(name='Continue',button_type='primary')\n",
    "        self.continue_button.on_click(self.on_click_continue)\n",
    "        \n",
    "    def on_click_continue(self, event):\n",
    "        self.ready=True\n",
    "    \n",
    "    @param.output('text')\n",
    "    def output(self):\n",
    "        text = self.text_input.value\n",
    "        return text\n",
    "        \n",
    "    def panel(self):\n",
    "        return pn.Column(self.text_input,\n",
    "                  self.continue_button\n",
    "                 )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Stage2` is going to display a single line of static text that will display what the user entered in `Stage1`.  Below, you can see that `text` was defined again as a `param.String`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stage2(param.Parameterized):\n",
    "    \n",
    "    \n",
    "    text = param.String()\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.text_display = pn.widgets.StaticText(name='Previously, you typed ', value=self.text)\n",
    "        \n",
    "    def panel(self):\n",
    "        return pn.Column(self.text_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our classes are defined, we can add the stages to the pipeline.  Below, you'll notice that each stage has string input that will serve as the string identifier for this stage, and then the second input is the class being added in this stage.  Here I have added a `\"Stage 1\"` and `\"Stage 2\"`.  \n",
    "\n",
    "Earlier, I mentioned having a `ready` parameter defined.  When adding a stage, you can specify the `ready_parameter` and set `auto_advance` to True, which will cause the next stage to appear when that `ready_parameter` is triggered.  \n",
    "\n",
    "After adding stages, you will define the relationship between the stages by calling the `define_graph` method.  This will determine the order of stages.  Here we will start with `Stage 1` then move to `Stage 2`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag.add_stage(\n",
    "    'Stage 1',\n",
    "    stage1,\n",
    "    ready_parameter='ready',\n",
    "    auto_advance=True\n",
    ")\n",
    "\n",
    "dag.add_stage(\n",
    "            'Stage 2',\n",
    "            stage2,\n",
    "            )\n",
    "\n",
    "dag.define_graph(\n",
    "            {'Stage 1': 'Stage 2',\n",
    "             }\n",
    "            )\n",
    "\n",
    "\n",
    "example_app = pn.Column(dag.stage).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view our app and confirm it does what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build much for elaborate pipelines with more stages, or even have branching stages that depend on user input.  Its quite flexible.  \n",
    "\n",
    "After seeing this simple example, I will now insert a bit more complicated classes into a pipeline the same way I did above. \n",
    "\n",
    "This panel app will display several tabs with different choices for a user to select for different pre-processing options in an NLP task.  When the user is ready to click `continue`, the pre-processing is completed and the next stage will display some options for testing and training a sentiment analysis model.  Currently, I don't have many choices implemented, but the structure is there to build upon. \n",
    "\n",
    "The two classes are displayed here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "\n",
    "from nltk.stem import (PorterStemmer, SnowballStemmer)\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "class PreProcessor(param.Parameterized):\n",
    "    \n",
    "    # df will be the variable holding the dataframe of text\n",
    "    df = param.DataFrame()\n",
    "    # title to display for each tab\n",
    "    name_of_page = param.String(default = 'Name of page')\n",
    "    # dataframe to display.\n",
    "    display_df = param.DataFrame(default = pd.DataFrame())\n",
    "    # stopword_df is the dataframe containing the stopewords\n",
    "    stopword_df = param.DataFrame(default = pd.DataFrame())\n",
    "    \n",
    "    stopwords = param.List(default = [])\n",
    "    X = param.Array(default = None)\n",
    "    \n",
    "    # *****NEW***********\n",
    "    ready = param.Boolean(\n",
    "        default=False,\n",
    "        doc='trigger for moving to the next page',\n",
    "        )   \n",
    "    # *******************\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # button for the pre-processing page\n",
    "        self.continue_button = pn.widgets.Button(name='Continue',\n",
    "                                                 width = 100,\n",
    "                                                 button_type='primary')\n",
    "\n",
    "        self.continue_button.on_click(self.continue_ready)\n",
    "        \n",
    "        # load text widgets \n",
    "        self.header_checkbox = pn.widgets.Checkbox(name='Header included in file')\n",
    "        self.load_file = pn.widgets.FileInput()\n",
    "        self.load_file.link(self.df, callbacks={'value': self.load_df})\n",
    "        self.header_checkbox = pn.widgets.Checkbox(name='Header included in file')\n",
    "        \n",
    "        # tokenize widgets\n",
    "        self.search_pattern_input = pn.widgets.TextInput(name='Search Pattern', value = '\\w+', width = 100)\n",
    "        \n",
    "        # remove stop words widgets\n",
    "        self.load_words_button = pn.widgets.FileInput()\n",
    "        self.load_words_button.link(self.stopwords, callbacks={'value': self.load_stopwords})\n",
    "        \n",
    "        # stem widgets\n",
    "        self.stem_choice = pn.widgets.Select(name='Select', options=['Porter', 'Snowball'])\n",
    "        \n",
    "        # embedding widgets\n",
    "        \n",
    "        self.we_model = pn.widgets.Select(name='Select', options=['SKLearn Count Vectorizer'])\n",
    "\n",
    "        \n",
    "    @param.output('X', 'display_df')\n",
    "    def output(self):\n",
    "        return self.X, self.display_df\n",
    "    \n",
    "    \n",
    "    @param.depends('display_df')\n",
    "    def df_pane(self):\n",
    "        return pn.WidgetBox(self.display_df,\n",
    "                           height = 300,\n",
    "                           width = 400)\n",
    "    \n",
    "    # load text page functions\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    def load_df(self, df, event):\n",
    "        info = io.BytesIO(self.load_file.value)\n",
    "        if self.header_checkbox.value==True:\n",
    "            self.df = pd.read_csv(info)\n",
    "        else:\n",
    "            self.df = pd.read_csv(info, sep='\\n', header = None, names=['text'])\n",
    "        \n",
    "        self.display_df = self.df\n",
    "    \n",
    "    def load_text_page(self):\n",
    "        helper_text = (\n",
    "            \"This simple Sentiment Analysis NLP app will allow you to select a few different options \" +\n",
    "            \"for some preprocessing steps to prepare your text for testing and training. \" +\n",
    "            \"It will then allow you to choose a model to train, the percentage of data to \" +\n",
    "            \"preserve for test, while the rest will be used to train the model.  Finally, \" +\n",
    "            \"some initial metrics will be displayed to determine how well the model did to predict \" +\n",
    "            \"the testing results.\" +\n",
    "            \" \" +\n",
    "            \"Please choose a csv file that contains lines of text to analyze.  This text should \" +\n",
    "            \"have a text column as well as a sentiment column.  If there is a header included in the file, \" +\n",
    "            \"make sure to check the header checkbox.\"\n",
    "        )\n",
    "        return pn.Row(\n",
    "                pn.Column(\n",
    "                    pn.pane.Markdown(f'##Load Text:'),\n",
    "                    pn.Column(\n",
    "                        helper_text,\n",
    "                         self.header_checkbox,\n",
    "                         self.load_file\n",
    "                        ),\n",
    "                ),\n",
    "                pn.Column(\n",
    "                    pn.Spacer(height=52),\n",
    "                    self.df_pane,\n",
    "                    \n",
    "                )\n",
    "        \n",
    "        )\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # tokenize page options\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    def tokenize_option_page(self):\n",
    "        \n",
    "        help_text = (\"Tokenization will break your text into a list of single articles \" +\n",
    "            \"(ex. ['A', 'cat', 'walked', 'into', 'the', 'house', '.']).  Specify a regular \" +\n",
    "            \"expression (regex) search pattern to use for splitting the text.\")\n",
    "        \n",
    "        return pn.Column(\n",
    "                    pn.pane.Markdown(f'##Tokenize options:'),\n",
    "                    pn.WidgetBox(help_text, self.search_pattern_input,\n",
    "                                    height = 300,\n",
    "                                    width = 300\n",
    "        \n",
    "                                )\n",
    "                )\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # remove stopwords page \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def remove_stopwords_page(self):\n",
    "        \n",
    "        help_text = (\n",
    "            \"Stop words are words that do not add any value to the sentiment of the text. \" +\n",
    "            \"Removing them may improve your sentiment results.  You may load a list of stop words \" +\n",
    "            \"to exclude from your text.\"\n",
    "        )\n",
    "        return pn.Row(\n",
    "                pn.Column(\n",
    "                    pn.pane.Markdown(f'##Load Stopwords:'),\n",
    "                    pn.WidgetBox(help_text, self.load_words_button,\n",
    "                                    height = 300,\n",
    "                                    width = 300\n",
    "        \n",
    "                    )\n",
    "                ),\n",
    "                pn.Column(\n",
    "                    pn.Spacer(height=52),\n",
    "                    pn.WidgetBox(self.stopword_df,\n",
    "                           height = 300,\n",
    "                           width = 400)\n",
    "                    \n",
    "                )\n",
    "        )\n",
    "    \n",
    "    def load_stopwords(self, stopwords, event):\n",
    "        info = io.BytesIO(self.load_words_button.value)\n",
    "        self.stopwords = pd.read_pickle(info)\n",
    "        self.stopword_df = pd.DataFrame({'stop words': self.stopwords})\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # stemming page \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def stemmer_page(self):\n",
    "        help_text = (\n",
    "            \"Stemming is a normalization step for the words in your text.  Something that is \" +\n",
    "            \"plural should probably still be clumped together with a singular version of a word, \" +\n",
    "            \"for example.  Stemming will basically remove the ends of words.  Here you can choose \" + \n",
    "            \"between a Porter Stemmer or Snowball Stemmer. Porter is a little less aggressive than \" +\n",
    "            \"Snowball, however, Snowball is considered a slight improvement over Porter.\"\n",
    "        )\n",
    "        return pn.Column(\n",
    "                    pn.pane.Markdown(f'##Stemmer options:'),\n",
    "                    pn.WidgetBox(help_text, self.stem_choice,\n",
    "                height = 300,\n",
    "                width = 300)\n",
    "                )\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    # embedding page \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    def word_embedding_page(self):\n",
    "        \n",
    "        help_text = (\"Embedding the process of turning words into numerical vectors. \" +\n",
    "                    \"There have been several algorithms developed to do this, however, currently in this \" +\n",
    "                    \"app, the sklearn count vectorizer is available. This algorithm will return a sparse \" +\n",
    "                    \"matrix represention of all the words in your text.\"\n",
    "                    )\n",
    "        \n",
    "        \n",
    "        \n",
    "        return pn.Column(\n",
    "                    pn.pane.Markdown(f'##Choose embedding model:'),\n",
    "                    pn.WidgetBox(help_text, self.we_model,\n",
    "                            height = 300,\n",
    "                            width = 300\n",
    "        \n",
    "                    )\n",
    "        \n",
    "                )\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------------------\n",
    "          \n",
    "    def continue_ready(self, event):\n",
    "\n",
    "        # Set up for tokenization\n",
    "        tokenizer = RegexpTokenizer(self.search_pattern_input.value)\n",
    "\n",
    "        # Set up for stemming\n",
    "        if self.stem_choice.value == 'Porter':\n",
    "            stemmer = PorterStemmer() \n",
    "        else:\n",
    "            stemmer = SnowballStemmer()\n",
    "\n",
    "        # Set up for embedding\n",
    "        if self.we_model.value == 'SKLearn Count Vectorizer':\n",
    "            # Create a vectorizer instance\n",
    "            vectorizer = CountVectorizer(max_features=1000)\n",
    "\n",
    "        corpus = []\n",
    "        #loop through each line of data\n",
    "        for n in range(len(self.display_df)):  \n",
    "            sentence = self.display_df.iloc[n].text\n",
    "\n",
    "            #1. Tokenize\n",
    "            tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "            #2. remove stop words\n",
    "            tokens_no_sw = [word for word in tokens if not word in self.stopwords]\n",
    "\n",
    "            #3. stem the remaining words\n",
    "            stem_words = [stemmer.stem(x) for x in tokens_no_sw]\n",
    "\n",
    "            #Join the words back together as one string and append this string to your corpus.\n",
    "            corpus.append(' '.join(stem_words))\n",
    "\n",
    "        X = vectorizer.fit_transform(corpus).toarray()\n",
    "        labels = self.display_df['sentiment']\n",
    "\n",
    "        xlist = []\n",
    "        for n in range(len(X)):\n",
    "            xlist.append(list(X[n]))\n",
    "        self.X = X\n",
    "        self.display_df = pd.DataFrame({'embeddings': xlist, 'sentiment': labels})\n",
    "        \n",
    "        self.ready = True\n",
    "    \n",
    "    def panel(self):\n",
    "        \n",
    "        return pn.Column(\n",
    "            pn.Tabs(\n",
    "                ('Load Text', self.load_text_page),\n",
    "                ('Tokenize', self.tokenize_option_page),\n",
    "                ('Remove Stopwords', self.remove_stopwords_page),\n",
    "                ('Stem', self.stemmer_page),\n",
    "                ('Embed', self.word_embedding_page)\n",
    "                ),\n",
    "            self.continue_button\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "import param\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class trainer(param.Parameterized):\n",
    "    \n",
    "    display_df = param.DataFrame(default = pd.DataFrame())\n",
    "    \n",
    "    results = param.Boolean(default = False)\n",
    "    \n",
    "    X = param.Array(default = None)\n",
    "    \n",
    "    result_string = param.String(default = '')\n",
    "\n",
    "    result_string = param.String('')\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.name_of_page = 'Test and Train'\n",
    "        \n",
    "        self.test_slider = pn.widgets.IntSlider(name='Test Percentage', start=0, end=100, step=10, value=20)\n",
    "\n",
    "        self.tt_button = pn.widgets.Button(name='Train and Test', button_type='primary')\n",
    "        self.tt_button.on_click(self.train_test)\n",
    "        \n",
    "        self.tt_model = pn.widgets.Select(name='Select', options=['Random Forrest Classifier'])\n",
    "        \n",
    "        \n",
    "    def train_test(self, event):\n",
    "        \n",
    "        #get values from sentiment.\n",
    "        self.display_df = convert_sentiment_values(self.display_df)\n",
    "        \n",
    "        y = self.display_df['label']\n",
    "        \n",
    "        #get train test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, y, test_size = self.test_slider.value/100, random_state = 0)\n",
    "        \n",
    "        \n",
    "        if self.tt_model.value == 'Random Forrest Classifier':\n",
    "            sentiment_classifier = RandomForestClassifier(n_estimators = 1000, random_state = 0)\n",
    "            \n",
    "            sentiment_classifier.fit(X_train, y_train)\n",
    "            \n",
    "            y_pred = sentiment_classifier.predict(X_test)\n",
    "            \n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.analyze()\n",
    "        \n",
    "    def analyze(self):\n",
    "        self.cm = confusion_matrix(self.y_test,self.y_pred)\n",
    "        self.cr = classification_report(self.y_test,self.y_pred)\n",
    "        self.acc_score = accuracy_score(self.y_test, self.y_pred)\n",
    "        \n",
    "        splits = self.cr.split('\\n')\n",
    "        cml = self.cm.tolist()\n",
    "        self.result_string = f\"\"\"\n",
    "            ### Classification Report\n",
    "            <pre>\n",
    "            {splits[0]}\n",
    "            {splits[1]}\n",
    "            {splits[2]}\n",
    "            {splits[3]}\n",
    "            {splits[4]}\n",
    "            {splits[5]}\n",
    "            {splits[6]}\n",
    "            {splits[7]}\n",
    "            {splits[8]}\n",
    "            </pre>\n",
    "            ### Confusion Matrix\n",
    "            <pre>\n",
    "            {cml[0]}\n",
    "            {cml[1]}\n",
    "\n",
    "            </pre>\n",
    "\n",
    "            ### Accuracy Score\n",
    "            <pre>\n",
    "            {round(self.acc_score, 4)}\n",
    "            </pre\n",
    "            \"\"\"\n",
    "        \n",
    "\n",
    "        self.results = True \n",
    "\n",
    "    def options_page(self, help_text):\n",
    "        \n",
    "        return pn.WidgetBox(help_text, self.tt_model,\n",
    "                            self.test_slider,\n",
    "                            self.tt_button,\n",
    "                height = 375,\n",
    "                width = 300\n",
    "        \n",
    "        )\n",
    "        \n",
    "    @pn.depends('results')\n",
    "    def df_pane(self):\n",
    "        \n",
    "        if self.results == False:\n",
    "            self.result_pane = self.display_df\n",
    "            \n",
    "        else:\n",
    "            self.result_pane = pn.pane.Markdown(f\"\"\"\n",
    "                {self.result_string}\n",
    "                \"\"\", width = 500, height = 350)\n",
    "        \n",
    "        return pn.WidgetBox(self.result_pane,\n",
    "                           height = 375,\n",
    "                           width = 450)\n",
    "        \n",
    "\n",
    "\n",
    "    def panel(self):\n",
    "        \n",
    "        help_text = (\n",
    "            \"Your text will now be trained and tested using a selected model.  You may \" +\n",
    "            \"choose a percentage of your data to reserve for testing, the rest will be used for \" +\n",
    "            \"training.  For example, if I reserve 20%, the rest of the 80% will be used for training \" +\n",
    "            \"and the 20% will be used to determine how well the trained model does assigning a \" +\n",
    "            \"sentiment label to the testing text.  Currently, the only model available is the sklearn \" +\n",
    "            \"Random Forrest Classifier model.\"\n",
    "        )\n",
    "        \n",
    "        return pn.Row(\n",
    "                pn.Column(\n",
    "                    pn.pane.Markdown(f'##Train and Test'),\n",
    "                    self.options_page(help_text),\n",
    "                ),\n",
    "                pn.Column(\n",
    "                    pn.Spacer(height=52),\n",
    "                    self.df_pane,\n",
    "                    \n",
    "                )\n",
    "        \n",
    "        )\n",
    "    \n",
    "    \n",
    "def convert_sentiment_values(df, col = 'sentiment'):\n",
    "    vals = df['sentiment'].unique()\n",
    "    df['label'] = 0\n",
    "\n",
    "    for n in range(len(vals)):\n",
    "        df['label'] = [n if df[col][x] == vals[n] else df['label'][x] for x in range(len(df[col]))]\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is established just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = pn.pipeline.Pipeline(inherit_params=False)\n",
    "\n",
    "dag.add_stage(\n",
    "    'Preprocess',\n",
    "    PreProcessor,\n",
    "    ready_parameter='ready',\n",
    "    auto_advance=True\n",
    ")\n",
    "\n",
    "dag.add_stage(\n",
    "            'Testing',\n",
    "            trainer,\n",
    "            ready_parameter='ready',\n",
    "            auto_advance=True,\n",
    "            )\n",
    "\n",
    "dag.define_graph(\n",
    "            {'Preprocess': 'Testing',\n",
    "             }\n",
    "            )\n",
    "\n",
    "\n",
    "SentimentApp = pn.Column(dag.stage).servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can view our new app:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For more details on how I built the first page of this app, I wrote up my thought process to develop this stage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
